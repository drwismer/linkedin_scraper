{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e33355e2-eaed-4425-b1e2-c0e79ec602c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import time\n",
    "\n",
    "# Set up Firefox driver\n",
    "geckodriver = \"/Applications/geckodriver\"\n",
    "os.environ['webdriver.firefox.driver'] = geckodriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "af1b0b55-0905-41ed-8836-ae75f51dd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t&H(YwSS8:V5E?c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fa689c0a-3c53-4c8e-9e1e-99609fbac831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide job alert URL's with descriptions\n",
    "job_alerts = {#'Small Company Remote Analyst US' : 'https://www.linkedin.com/jobs/search/?f_C=2029%2C68543%2C2658876%2C3477522%2C3806620%2C6459033%2C18696467%2C312538%2C3765675%2C3293310%2C1253671%2C2908815%2C3881453%2C1835869%2C2029368%2C279570%2C2503130%2C7944399%2C1110454%2C2748615%2C3640016%2C6591023%2C10643112%2C18348748%2C2464624%2C5233302%2C10345478%2C1120204%2C14041470%2C18917297%2C19006475%2C19023241%2C19852792%2C2120791%2C2544439%2C2575799%2C27116184%2C2762432%2C28639174%2C3317416%2C35539062%2C3818105%2C3832515%2C3896605%2C6633924%2C6653417%2C72307365&f_WT=2&geoId=103644278&keywords=analyst&location=United%20States',\n",
    "              #'Big Company Remote Analyst US' : 'https://www.linkedin.com/jobs/search?keywords=Data%20Analyst&location=United%20States&locationId=&geoId=103644278&f_TPR=&f_C=1586%2C3185%2C2382910%2C2532259%2C96622%2C20226%2C1028%2C10667%2C1441%2C1063%2C1815218%2C2672915%2C675562%2C3608%2C15088102%2C732400%2C13990%2C54178%2C1337%2C19022%2C19857%2C1512%2C22688%2C1033%2C3254263%2C1035%2C1480%2C206993%2C1463%2C165697%2C2748615%2C1482%2C166000%2C2029%2C822535%2C162479%2C165158%2C207470%2C1038%2C1103%2C1307%2C1371%2C147977%2C16140%2C2271%2C2658876%2C2908815%2C309694%2C3595%2C51941%2C6633924%2C665858%2C76987811&f_JT=F%2CC&f_WT=2&position=1&pageNum=0',\n",
    "              #'ML Remote US' : 'https://www.linkedin.com/comm/jobs/search?savedSearchId=1726769010&alertAction=viewjobs&f_TPR=a1646969285-&savedSearchAuthToken=1%26AQEw-KRlCuTsuAAAAX-bEW9MIlDcL9bCszsay7OgwQiPRDn-8AsPZe_DmrL1NW3J6Be7zJYC_4PDtKpPaCtO5fu99p90e9AMwGz8ikB6k1qVuburQhBZ9afcVyS-ChJdV2VlCOwGGs0B6p5fqoK8jfuSMlQbFX3fXA5E9WM_AAzGSlT3JxYBKggelYnNuVBR3iEqT91KyLfJwY87_6ujI4sWzymir3IVI2X5qKXiOsyM9W-cvroybKhaGtmj6B2pZwgtBtOlReSXGSaPRp_w7mDkzXSpfcXj47GRk3vRl5_Bwoe05lY%26Ab1rT8684_eJGFHi02PCijuFMJQR&midToken=AQGOAaXZ2Mv6pw&midSig=0nOMaFZ6zM_W81&trk=eml-email_job_alert_confirmation_01-job_alert-0-header_mercado&trkEmail=eml-email_job_alert_confirmation_01-job_alert-0-header_mercado-null-39xk3l%7El0vv2kjr%7Ep3-null-jobs%7Ejserp%7Esearch&lipi=urn%3Ali%3Apage%3Aemail_email_job_alert_confirmation_01%3BHzdSji8SSyaBBISxzuCUSA%3D%3D',\n",
    "              #'Data Analyst Seattle' : 'https://www.linkedin.com/jobs/search/?f_E=2%252C3&f_JT=F%252CC&f_WT=2&geoId=103644278&keywords=data%20analyst%20seattle&location=United%20States',\n",
    "              #'Top Small Companies to Work Data Analyst' : 'https://www.linkedin.com/jobs/search/?f_C=1866670%2C97475%2C1253671%2C5243263%2C3806620%2C8495%2C1030330%2C10879774%2C3677944%2C3112877%2C3782894%2C3877505%2C1175268%2C6459033%2C25016898%2C25237%2C2973445%2C377671%2C41771%2C425337%2C510820%2C1165219%2C156534%2C16162690%2C17895640%2C222181%2C2820889%2C28669481%2C2908815%2C2977830%2C3056596%2C33189811%2C34957318%2C3961599%2C40026%2C5073200%2C5225921%2C631652%2C68648187%2C71655160%2C74157&f_WT=2&keywords=data%20analyst',\n",
    "              #'Great Small Places to Work' : 'https://www.linkedin.com/jobs/search/?f_C=3126445%2C147977%2C18373097%2C5101804%2C11220691%2C3640016%2C137338%2C7587729%2C18880849%2C224232%2C10526429%2C18226665%2C1637984%2C3809194%2C308865%2C222181%2C34224678%2C231741%2C9451029%2C3738695%2C792882%2C2582861%2C21837%2C3089380%2C210676%2C5243263%2C2225282%2C15175997%2C863947%2C14059116%2C2029368%2C807257&f_WT=2&geoId=103644278&keywords=analyst&location=United%20States&sortBy=DD',\n",
    "              'More Analyst Jobs' : 'https://www.linkedin.com/jobs/search/?alertAction=viewjobs&f_EA=%5B%22true%22%5D&f_F=%5B%22anls%22%2C%22rsch%22%2C%22cnsl%22%2C%22fin%22%2C%22mrkt%22%2C%22bd%22%2C%22prdm%22%5D&f_JT=%5B%22F%22%5D&f_T=%5B%22340%22%2C%2229%22%2C%22194%22%2C%2226610%22%2C%222463%22%5D&f_WT=%5B%222%22%5D&geoId=103644278&keywords=data%20analyst%20-%22edward%20jones%22%20-pwc%20-merkle&location=United%20States'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "89fdf820-3fe3-48f0-85a1-278e7775cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Selenium driver\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b5673ae3-6036-42b0-88e9-8b635c16e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up empty dataframe to load job data\n",
    "job_data = pd.DataFrame(columns=['ID',\n",
    "                                 'Date',\n",
    "                                 'Company',\n",
    "                                 'Title',\n",
    "                                 'Location',\n",
    "                                 'Description',\n",
    "                                 'Link'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2931be0e-3a3e-4bec-ae59-2abc57aa198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More Analyst Jobs\n",
      "Job Count: 1208\n",
      "Length: 372\n"
     ]
    }
   ],
   "source": [
    "for key in job_alerts:\n",
    "    \n",
    "    print(key)\n",
    "    \n",
    "    # Go to web page\n",
    "    driver.get(job_alerts[key]);\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Find job count\n",
    "    attempt = 0\n",
    "    stop = False\n",
    "    \n",
    "    while (stop == False) & (attempt < 5):\n",
    "        try: \n",
    "            driver.get(job_alerts[key]);\n",
    "            time.sleep(5)\n",
    "            job_count = int(driver.find_element('css selector', 'small.display-flex').get_attribute('innerText').split(' ')[0].replace(',', ''))\n",
    "            #job_count = int(''.join(re.findall('\\d+', driver.find_element('css selector', 'h1>span').get_attribute('innerText'))))\n",
    "            job_lists = driver.find_element('css selector', '.jobs-search-results__list')\n",
    "            jobs = job_lists.find_elements('tag name', 'li')\n",
    "            stop = True\n",
    "        except:\n",
    "            attempt += 1\n",
    "            print('Attempt #' + str(attempt) + ' failed')\n",
    "            next\n",
    "    \n",
    "    print('Job Count: ' + str(job_count))\n",
    "    \n",
    "    if attempt == 5:\n",
    "        print('Scrape failed for ' + key)\n",
    "        next\n",
    "\n",
    "    # Check for pagination    \n",
    "    try:\n",
    "        final_page = driver.find_element('class name', 'jobs-search-two-pane__pagination')\\\n",
    "                        .find_element('tag name', 'div')\\\n",
    "                        .find_element('tag name', 'ul')\\\n",
    "                        .find_elements('tag name', 'li')[-1]\\\n",
    "                        .get_attribute('innerText')\n",
    "    \n",
    "        start_list = [x * 25 for x in range(0, int(final_page))]\n",
    "        pages = True\n",
    "    except:\n",
    "        pages = False\n",
    "    \n",
    "    # Set up lists of job details to be loaded to dataframe\n",
    "    job_id= []\n",
    "    job_title = []\n",
    "    company_name = []\n",
    "    location = []\n",
    "    date = []\n",
    "    job_link = []\n",
    "    \n",
    "    if pages:\n",
    "        # Go to each page to get job details\n",
    "        for start in start_list:\n",
    "            try:\n",
    "                driver.get(job_alerts[key] + '&start=' + str(start))\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Scroll to footer to load more jobs\n",
    "                list_items = driver.find_element('css selector', '.jobs-search-results__list').find_elements('tag name', 'li')\n",
    "\n",
    "                for i in range(1,10):\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", list_items[int(len(list_items) * i / 10)])\n",
    "                    time.sleep(2)\n",
    "\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", list_items[-1])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "            jobs = soup.find('ul', {'class': 'jobs-search-results__list list-style-none'})\\\n",
    "                            .find_all('li', {'class': 'jobs-search-results__list-item occludable-update p0 relative ember-view'})\n",
    "\n",
    "            for job in jobs:\n",
    "                try:\n",
    "                    job_id0 = job.find('div').find('div')['data-job-id']\n",
    "                    job_title0 = job.find('div', {'class': 'full-width artdeco-entity-lockup__title ember-view'}).text.strip()\n",
    "                    company_name0 = job.find('div', {'class': 'artdeco-entity-lockup__subtitle ember-view'}).text.strip()\n",
    "                    location0 = ' - '.join([x.strip() for x in job.find('div', {'class': 'artdeco-entity-lockup__caption ember-view'}).text.split('\\n') if x.strip()])\n",
    "                    job_link0 = 'https://www.linkedin.com/' + job.find('div', {'class': 'full-width artdeco-entity-lockup__title ember-view'}).find('a', href=True)['href']\n",
    "                    date0 = ''\n",
    "\n",
    "                    job_id.append(job_id0)\n",
    "                    job_title.append(job_title0)\n",
    "                    company_name.append(company_name0)\n",
    "                    location.append(location0)\n",
    "                    date.append(date0)\n",
    "                    job_link.append(job_link0)\n",
    "                \n",
    "                except:\n",
    "                    next\n",
    "    else:\n",
    "        # Scroll to the bottom of all jobs\n",
    "        i = 1\n",
    "\n",
    "        while (len(jobs) < job_count and i < 100): \n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "\n",
    "            try:\n",
    "                driver.find_element('xpath', '/html/body/div[1]/div/main/section[2]/button').click()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                time.sleep(3)\n",
    "\n",
    "            job_lists = driver.find_element('css selector', '.jobs-search-results__list')\n",
    "            jobs = job_lists.find_elements('tag name', 'li')\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # Set up list of jobs on page\n",
    "        job_lists = driver.find_element('css selector', '.jobs-search-results__list')\n",
    "        jobs = job_lists.find_elements('tag name', 'li')\n",
    "\n",
    "        for job in jobs:\n",
    "            for job in jobs:\n",
    "                try:\n",
    "                    job_id0 = job.find_element('css selector', 'div').find_element('css selector', 'div').get_attribute('data-job-id')\n",
    "                    job_id.append(job_id0)\n",
    "                except:\n",
    "                    jobs.remove(jobs)\n",
    "                    next\n",
    "\n",
    "                job_title0 = job.find_element('css selector', 'div').find_element('css selector', 'div').find_element('css selector', 'div').find_elements('css selector', 'div')[1].find_elements('css selector', 'div')[0].get_attribute('innerText')\n",
    "                job_title.append(job_title0)\n",
    "\n",
    "                company_name0 = job.find_element('css selector', 'div').find_element('css selector', 'div').find_element('css selector', 'div').find_elements('css selector', 'div')[1].find_elements('css selector', 'div')[1].get_attribute('innerText')\n",
    "                company_name.append(company_name0)\n",
    "                location0 = ' - '.join(job.find_element('css selector', 'div').find_element('css selector', 'div').find_element('css selector', 'div').find_elements('css selector', 'div')[1].find_elements('css selector', 'div')[2].get_attribute('innerText').split('\\n'))\n",
    "                location.append(location0)\n",
    "\n",
    "                try:\n",
    "                    date0 = job.find_element('css selector', 'div>div>time').get_attribute('datetime')\n",
    "                    date.append(date0)\n",
    "                except:\n",
    "                    date.append('')\n",
    "\n",
    "                job_link0 = job.find_element('css selector', 'div').find_element('css selector', 'div').find_element('css selector', 'div').find_elements('css selector', 'div')[1].find_elements('css selector', 'a')[0].get_attribute('href')\n",
    "                job_link.append(job_link0)\n",
    "    \n",
    "    min_length = min(len(job_id),\n",
    "                     len(job_title),\n",
    "                     len(company_name),\n",
    "                     len(date),\n",
    "                     len(location),\n",
    "                     len(job_link)\n",
    "                    )\n",
    "    \n",
    "    job_id = job_id[0 : min_length - 1]\n",
    "    job_title = job_title[0 : min_length - 1]\n",
    "    job_link = job_link[0 : min_length - 1]\n",
    "    location = company_name[0 : min_length - 1]\n",
    "    company_name = company_name[0 : min_length - 1]\n",
    "    date = date[0 : min_length - 1]\n",
    "    job_link = job_link[0 : min_length - 1]\n",
    "                         \n",
    "\n",
    "    # Get job description and additional details from each job page to load to dataframe\n",
    "    jd = []\n",
    "\n",
    "    for link in job_link:\n",
    "        driver.get(job_link[0])\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "        try:\n",
    "            jd0 = soup.find('div', {'id': \"job-details\"}).text.strip()\n",
    "            jd.append(jd0)\n",
    "        except AttributeError:\n",
    "            jd.append('')\n",
    "\n",
    "    # Create dataframe for current key in dictionary and amend to the full dataframe\n",
    "    key_data = pd.DataFrame({'ID': job_id,\n",
    "                             'Date': date,\n",
    "                             'Company': company_name,\n",
    "                             'Title': job_title,\n",
    "                             'Location': location,\n",
    "                             'Description': jd,\n",
    "                             'Link': job_link\n",
    "                            })\n",
    "    \n",
    "    print('Length: ' + str(len(key_data)))\n",
    "    job_data = job_data.append(key_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b7cfc8f7-6f89-4bb3-8735-db242e5b490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transorm job description column to lower case\n",
    "job_data['Description'] = job_data['Description'].str.lower()\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2f432db4-8d84-4968-856d-14b96dd7cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary columns to tag whether key phrases are included in job descriptions\n",
    "job_data['Remote'] = job_data['Description'].str.contains('remote').astype(int)\n",
    "job_data['Python'] = job_data['Description'].str.contains('python').astype(int)\n",
    "job_data['Programming'] = job_data['Description'].str.contains('programming').astype(int)\n",
    "job_data['ML'] = job_data['Description'].str.contains('machine learning').astype(int)\n",
    "job_data['SQL'] = job_data['Description'].str.contains('sql').astype(int)\n",
    "job_data['BI'] = job_data['Description'].str.contains('business intelligence').astype(int)\n",
    "job_data['Tableau'] = job_data['Description'].str.contains('tableau').astype(int)\n",
    "job_data['AB'] = job_data['Description'].str.contains('ab test | a/b test').astype(int)\n",
    "job_data['Forecasting'] = job_data['Description'].str.contains('forecast').astype(int)\n",
    "job_data['Revenue'] = job_data['Description'].str.contains('revenue').astype(int)\n",
    "\n",
    "job_data['Total Hits'] = job_data.loc[:,'Remote':].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "246a132e-6bda-437f-9707-a6045aa2167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "job_data = job_data[['ID',\n",
    "                     'Company',\n",
    "                     'Title',\n",
    "                     'Date',\n",
    "                     'Location',\n",
    "                     'Link',\n",
    "                     'Total Hits',\n",
    "                     'Remote',\n",
    "                     'Python',\n",
    "                     'Programming',\n",
    "                     'ML',\n",
    "                     'SQL',\n",
    "                     'BI',\n",
    "                     'Tableau',\n",
    "                     'AB',\n",
    "                     'Forecasting',\n",
    "                     'Revenue',\n",
    "                     'Description'\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5d5fa8be-9895-4426-8493-e3ca533d4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.to_csv('job_data_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538c14b-568f-4c0f-be24-ced4b3cc0b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
